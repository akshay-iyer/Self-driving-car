{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comma.ai speed prediction challenge ( MSE <4 achieved on validation dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Task is done using \"End to End Learning for Self-Driving Cars archtecture\" ( published in 2016). I have incorporated a few changes in the archtecture in the architecture to improve the results. The input data is the optical flow between the two consecutive images with some other transformations. The framework used is Pytorch. The final MSE is less than 4 on validation test. At the end of the notebook, I have predicted speed for Test.mp4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H3XKt_-czDwX"
   },
   "outputs": [],
   "source": [
    "# import cv2 \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage import io, transform\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ky3cLA21zDwa"
   },
   "outputs": [],
   "source": [
    "# to change the brightness\n",
    "def change_brightness(image, bright_factor):\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    hsv_image[:,:,2] = hsv_image[:,:,2] * bright_factor\n",
    "    image_rgb = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2RGB)\n",
    "    return image_rgb\n",
    "\n",
    "# to get the frames from the video\n",
    "def get_frames(filename):\n",
    "    vidcap = cv2.VideoCapture(filename)\n",
    "    success = True\n",
    "    data = []\n",
    "    while success:\n",
    "        success,image = vidcap.read()\n",
    "        if success:\n",
    "            data.append(image)\n",
    "    return data\n",
    "\n",
    "# to get the speed from the text file\n",
    "def get_speed_data(filename):\n",
    "    speed=[]\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            val = line.rstrip('\\n')\n",
    "            val = float(val)\n",
    "            speed.append(val)\n",
    "    return speed\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "vJWL3ac2zDwd",
    "outputId": "e43c23e4-134d-4b56-f12d-ca85bf0cf652"
   },
   "outputs": [],
   "source": [
    "# speed_data and images_data are lists that have the speed(target variable) and frames from video\n",
    "# please change the path if the train.mp4 and train.txt are in different folder\n",
    "\n",
    "path_txt = \"train.txt\"\n",
    "path_mp4 = \"train.mp4\"\n",
    "\n",
    "speed_data = get_speed_data(path_txt)\n",
    "images_data= get_frames(path_mp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fbaoiU7gzDwf"
   },
   "outputs": [],
   "source": [
    "# optical flow function\n",
    "def opticalFlowDense(frame1,frame2):\n",
    "    frame1 = frame1[200:400]\n",
    "    frame1 = cv2.resize(frame1, (0,0), fx = 0.4, fy=0.5)\n",
    "    frame2 = frame2[200:400]\n",
    "    frame2 = cv2.resize(frame2, (0,0), fx = 0.4, fy=0.5)\n",
    "    flow = np.zeros_like(frame1)\n",
    "    prev = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "    nxt = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    flow_mat = None\n",
    "    image_scale = 0.4\n",
    "    nb_images = 1\n",
    "    win_size = 12\n",
    "    nb_iterations = 2\n",
    "    deg_expansion = 8\n",
    "    STD = 1.2\n",
    "    extra = 0   \n",
    "    \n",
    "    flow = cv2.calcOpticalFlowFarneback(gray_current, gray_next,flow_mat,image_scale,nb_images, win_size, nb_iterations, deg_expansion, STD,0)\n",
    "    \n",
    "    mag, ang = cv2.cartToPolar(flow_data[...,0], flow_data[...,1])\n",
    "    flow[...,1] = 255\n",
    "    flow[...,0] = ang*180/np.pi/2\n",
    "    flow[...,2] = (mag *15).astype(int)\n",
    "    return flow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EFva7nKkzDwi"
   },
   "outputs": [],
   "source": [
    "# optical_flow_images is a list that contains opticalFlow flow between every two consecutive images\n",
    "# speed_Data_final ia average speed every two consecutive image\n",
    "\n",
    "optical_flow_images = []\n",
    "speed_Data_final = []\n",
    "for i in range(0,len(images_data)-1):\n",
    "    img = cv2.resize(opticalFlowDense(images_data[i],images_data[i+1]),(200,66))/255\n",
    "    optical_flow_images.append(img)\n",
    "    \n",
    "    mean_speed = (speed_data[i] + speed_data[i+1])/2\n",
    "    label = np.asarray(mean_speed,dtype= np.float32)\n",
    "    speed_Data_final.append(label)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qbW6kFVKzDwk"
   },
   "outputs": [],
   "source": [
    "# Training and validation split - 80/20\n",
    "\n",
    "train_data = optical_flow_images[:int(0.8*len(optical_flow_images))]\n",
    "train_labels = speed_Data_final[:int(0.8*len(speed_Data_final))]\n",
    "\n",
    "val_data = optical_flow_images[int(0.8*len(optical_flow_images)):]\n",
    "val_labels = speed_Data_final[int(0.8*len(speed_Data_final)):]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LaqXQCxuzDwo"
   },
   "outputs": [],
   "source": [
    "class imagedataset(Dataset):\n",
    "\n",
    "    def __init__(self,video_file,speed_file,transforms):\n",
    "        self.transforms = transforms\n",
    "        self.data   = video_file\n",
    "        self.labels = speed_file\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        img   = self.data[index]\n",
    "        label = self.labels[index]\n",
    "        transformed_image = self.transforms(img)  \n",
    "        return transformed_image,label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j5tlAsKazDwq"
   },
   "outputs": [],
   "source": [
    "## dataloader\n",
    "\n",
    "transformations = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_data = imagedataset(train_data,\n",
    "                          train_labels,\n",
    "                          transforms = transformations)\n",
    "val_data =   imagedataset(val_data,\n",
    "                          val_labels,\n",
    "                          transforms = transformations)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p_8DjrxmzDwz"
   },
   "outputs": [],
   "source": [
    "# CNN architecture - End-to-End Deep Learning for Self-Driving Cars Architecture with some modifications\n",
    "\n",
    "# Need to put drop out \n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        \n",
    "        # Convolution 1\n",
    "        self.cnn1 = nn.Conv2d(in_channels=3, out_channels=24, kernel_size=5, stride=2, padding=0)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        # Convolution 2\n",
    "        self.cnn2 = nn.Conv2d(in_channels=24, out_channels=36, kernel_size=5, stride=2, padding=0)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # Convolution 3\n",
    "        \n",
    "        self.cnn3 = nn.Conv2d(in_channels=36, out_channels=48, kernel_size=5, stride=2, padding=0)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout1=nn.Dropout(p=0.5)\n",
    "        \n",
    "        # Convolution 4\n",
    "        self.cnn4 = nn.Conv2d(in_channels=48, out_channels=64, kernel_size=3, stride=1, padding=0)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        \n",
    "        # Convolution 5\n",
    "        \n",
    "        self.cnn5 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=0)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        \n",
    "        # Fully connected 1 \n",
    "        #self.fc1 = nn.Linear(in_features=1280, out_features=100)\n",
    "        self.fc1 = nn.Linear(in_features=1152, out_features=100)\n",
    "        self.relu_fc1 = nn.ReLU()\n",
    "   \n",
    "        \n",
    "        self.fc2 = nn.Linear(in_features=100, out_features=50)\n",
    "        self.relu_fc2 = nn.ReLU()\n",
    "        \n",
    "        self.fc3 = nn.Linear(in_features=50, out_features=10)\n",
    "        self.relu_fc3 = nn.ReLU()\n",
    "        \n",
    "        self.fc4 = nn.Linear(in_features=10, out_features=1)\n",
    "\n",
    "  \n",
    "    def forward(self, x):\n",
    "        # Convolution 1\n",
    "        out = self.cnn1(x)\n",
    "        out = self.relu1(out)\n",
    "        \n",
    "        # Convolution 2 \n",
    "        out = self.cnn2(out)\n",
    "        out = self.relu2(out)\n",
    "\n",
    "        # Convolution 3 \n",
    "        out = self.cnn3(out)\n",
    "        out = self.relu3(out)\n",
    "        out = self.dropout1(out)\n",
    "\n",
    "        # Convolution 4 \n",
    "        out = self.cnn4(out)\n",
    "        out = self.relu4(out)\n",
    "\n",
    "        # Convolution 5 \n",
    "        out = self.cnn5(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.relu5(out)\n",
    "        \n",
    "        # Linear function \n",
    "        out = self.fc1(out)\n",
    "        out = self.relu_fc1(out)\n",
    "\n",
    " \n",
    "        out = self.fc2(out)\n",
    "        out = self.relu_fc2(out)\n",
    "\n",
    "        \n",
    "        out = self.fc3(out)\n",
    "        out = self.relu_fc3(out)\n",
    "        \n",
    "        out = self.fc4(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d1xzpw5YzDw6"
   },
   "outputs": [],
   "source": [
    "# Model, critieria, learning rate , optimizer\n",
    "model = CNNModel()\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = .0001\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nlRzH0_wzDw9"
   },
   "outputs": [],
   "source": [
    "# train Model\n",
    "\n",
    "import os\n",
    "num_epochs =160\n",
    "\n",
    "# IMP - Please provide path on which the model will be saved\n",
    "path= \" \"\n",
    "\n",
    "# Imp - Please select a threshold of MSE you want to stop the training at , else train for high number of epochs and select the best ones\n",
    "threshold = 5\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    total_train_loss =0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "   \n",
    "        images = images.float()\n",
    "        labels = labels.float()\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "          images = Variable(images.cuda())\n",
    "        else:\n",
    "          images = Variable(images)\n",
    "\n",
    "            \n",
    "        if torch.cuda.is_available():\n",
    "          labels = Variable(labels.cuda())\n",
    "        else:\n",
    "          labels = Variable(labels)\n",
    "\n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimiser.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updating parameters\n",
    "        optimiser.step()\n",
    "        \n",
    "        #running_loss += loss.item()\n",
    "        total_train_loss += loss.item()\n",
    "        \n",
    "    print(\"Epoch number : {} Training Loss : {} \".format( epoch+1,total_train_loss/len(train_loader))) \n",
    "       \n",
    "    # after every epoch, testing on validation set\n",
    "    total_val_loss = 0\n",
    "    for i, (images, labels) in enumerate(val_loader):\n",
    "        images = images.float()\n",
    "        labels = labels.float()\n",
    "      \n",
    "        if torch.cuda.is_available():\n",
    "          images = Variable(images.cuda())\n",
    "        else:\n",
    "          images = Variable(images)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "          labels = Variable(labels.cuda())\n",
    "        else:\n",
    "          labels = Variable(labels)\n",
    "        \n",
    "        val_outputs = model(images)\n",
    "        val_loss_size = criterion(val_outputs, labels)\n",
    "        total_val_loss += val_loss_size.item()\n",
    "    Validation_Loss = total_val_loss/len(val_loader)\n",
    "    print(\"Epoch number : {} Validation Loss : {} \".format( epoch+1, Validation_Loss)) \n",
    "    print(\" \")\n",
    "    print(\" \")\n",
    "    \n",
    "    # Saving model for each epoch\n",
    "    torch.save(model.state_dict(), os.path.join(path, 'epoch-{}.pth'.format(epoch)))\n",
    "    \n",
    "    if Validation_Loss<threshold:\n",
    "        print(\"Finished training\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WOt65gNnzDxB"
   },
   "outputs": [],
   "source": [
    "# Testing  on validation set again with batch size = 1\n",
    "\n",
    "import os\n",
    "criterion = nn.MSELoss()\n",
    "val_data = optical_flow_images[int(0.8*len(optical_flow_images)):]\n",
    "val_labels = speed_Data_final[int(0.8*len(speed_Data_final)):]\n",
    "\n",
    "\n",
    "transformations = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "val_data =   imagedataset(val_data,\n",
    "                          val_labels,\n",
    "                          transforms = transformations)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=1, shuffle=False)\n",
    "\n",
    "def MSE_val(model,val_loader):\n",
    "    total_val_loss = 0\n",
    "    pred =[]\n",
    "    for i, (images, labels) in enumerate(val_loader):\n",
    "        images = images.float()\n",
    "        labels = labels.float()\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "          images = Variable(images.cuda())\n",
    "        else:\n",
    "          images = Variable(images)\n",
    "        if torch.cuda.is_available():\n",
    "          labels = Variable(labels.cuda())\n",
    "        else:\n",
    "          labels = Variable(labels)\n",
    "        val_outputs = model(images)\n",
    "        item = val_outputs.detach().numpy()\n",
    "        pred.append(item)\n",
    "        val_loss_size = criterion(val_outputs, labels)\n",
    "        total_val_loss += val_loss_size.item()\n",
    "\n",
    "    Validation_Loss = total_val_loss/len(val_loader)\n",
    "    return Validation_Loss\n",
    "\n",
    "# loading the last epoch model\n",
    "the_model = CNNModel()\n",
    "\n",
    "# IMP - select the best epoch with min val MSE( or of your choice)\n",
    "\n",
    "epoch =\n",
    "the_model.load_state_dict(torch.load(os.path.join(path, 'epoch-{}.pth'.format(epoch))))\n",
    "the_model.eval()\n",
    "MSE_val = MSE_val(the_model,val_loader)\n",
    "\n",
    "print(MSE_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Result and conclusion : The final MSE is around 5 on validation set ( 20% of train.mp4 ) . The next task is to generate speed values for test.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zf1mcTy0zDxH"
   },
   "source": [
    "# Generate test.txt on test.mp4 data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fe9mm4nuzDxK"
   },
   "outputs": [],
   "source": [
    "# make sure you have test.mp4 in same folder or put the correct folder path\n",
    "Test_Data= get_frames(\"test.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D3KpvdjAzDxO"
   },
   "outputs": [],
   "source": [
    "optical_flow_images = []\n",
    "speed_Data_final = []\n",
    "for i in range(0,len(Test_Data)-1):\n",
    "    img = cv2.resize(opticalFlowDense(Test_Data[i],Test_Data[i+1]),(200,66))/255\n",
    "    optical_flow_images.append(img)\n",
    "    speed_Data_final.append(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2tjXOG7XzDxQ"
   },
   "outputs": [],
   "source": [
    "test_data = optical_flow_images\n",
    "test_labels = speed_Data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k3hLM77izDxR"
   },
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([transforms.ToTensor()])\n",
    "test_data =   imagedataset(test_data,\n",
    "                          test_labels,\n",
    "                          transforms = transformations)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "crtrZF9SzDxU"
   },
   "outputs": [],
   "source": [
    "the_model = CNNModel()\n",
    "the_model.load_state_dict(torch.load(os.path.join(path, 'epoch-{}.pth'.format(epoch))))\n",
    "the_model.eval()\n",
    "\n",
    "# testing for complete validation set (not test), batch size = 1\n",
    "import os\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def predict(model,val_loader):\n",
    "    total_val_loss = 0\n",
    "    list =[]\n",
    "    for i, (images, labels) in enumerate(val_loader):\n",
    "        images = images.float()\n",
    "        labels = labels.float()\n",
    "        if torch.cuda.is_available():\n",
    "          images = Variable(images.cuda())\n",
    "        else:\n",
    "          images = Variable(images)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "          labels = Variable(labels.cuda())\n",
    "        else:\n",
    "          labels = Variable(labels)\n",
    "        val_outputs = model(images)\n",
    "        item = val_outputs.detach().numpy()\n",
    "        list.append(item)\n",
    "    return list\n",
    "\n",
    "#predict using the last model\n",
    "result = predict(the_model,val_loader)\n",
    "\n",
    "print(len(test_data))\n",
    "# taking only the values and appeneding in a list\n",
    "final_result =[]\n",
    "for i in range(len(test_data)):\n",
    "    final_result.append(result[i][0][0])\n",
    "    \n",
    "# adding the last value which missed because of opticalflow\n",
    "final_result.append(final_result[-3])\n",
    "\n",
    "with open('result_final.txt', 'w') as f:\n",
    "    for item in final_result:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": " SDC- 7.7 MSE Sol  - Sunday.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
